{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Trending\n",
    "- The **Trending API** and **Topic API** is derived by an emulater named [网易MuMu模拟器](https://mumu.163.com/), and [Charles Proxy](https://www.charlesproxy.com/);\n",
    "- Here I use the scraped API of CSDN user [考古学家lx](https://me.csdn.net/weixin_43582101) directly;\n",
    "- It is not an official API [[Reference]](https://blog.csdn.net/weixin_43582101/article/details/103791795)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last update time: 2020-03-02 16:33:47\n"
     ]
    }
   ],
   "source": [
    "trending_api = 'https://aweme-hl.snssdk.com/aweme/v1/hot/search/list/?detail_list=1&mac_address=08:00:27:29:D2:F5&os_api=23&device_type=MI%205s&device_platform=android&ssmix=a&iid=92152480453&manifest_version_code=860&dpi=320&uuid=008796750074613&version_code=860&app_name=aweme&version_name=8.6.0&ts=1577932778&openudid=c055533a0591b2dc&device_id=69918538596&resolution=810*1440&os_version=6.0.1&language=zh&device_brand=Xiaomi&app_type=normal&ac=wifi&update_version_code=8602&aid=1128&channel=tengxun_new&_rticket=1577932779592'\n",
    "re=requests.get(trending_api)\n",
    "soup=bs.BeautifulSoup(re.content,'html.parser')\n",
    "last_update = json.loads(soup.text)['data']['active_time']\n",
    "trending_data = json.loads(soup.text)['data']['word_list']\n",
    "trend = pd.DataFrame(trending_data)\n",
    "date=last_update.split(' ')[0]\n",
    "print('The last update time: '+last_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_cover=[]\n",
    "for i in trend['word_cover']:\n",
    "    if type(i)==dict:\n",
    "        Word_cover.append(i['url_list'][0])\n",
    "    else:\n",
    "        Word_cover.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = trend.drop(columns = ['word_cover','challenge_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>position</th>\n",
       "      <th>video_count</th>\n",
       "      <th>group_id</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word</th>\n",
       "      <th>hot_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>6647582024964068622</td>\n",
       "      <td>1</td>\n",
       "      <td>甩头发换装</td>\n",
       "      <td>11782203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6799126825244038407</td>\n",
       "      <td>1</td>\n",
       "      <td>一个人前后反差可以有多大</td>\n",
       "      <td>8092958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>6797941205557581067</td>\n",
       "      <td>1</td>\n",
       "      <td>刑释人员离汉抵京调查结果</td>\n",
       "      <td>7571719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  position  video_count             group_id  word_type          word  \\\n",
       "0      0         1           39  6647582024964068622          1         甩头发换装   \n",
       "1      0         2            1  6799126825244038407          1  一个人前后反差可以有多大   \n",
       "2      0         3           25  6797941205557581067          1  刑释人员离汉抵京调查结果   \n",
       "\n",
       "   hot_value  \n",
       "0   11782203  \n",
       "1    8092958  \n",
       "2    7571719  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trend.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_path(path):\n",
    "    folder = os.path.exists(path)\n",
    "    if not folder:\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>position</th>\n",
       "      <th>video_count</th>\n",
       "      <th>group_id</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word</th>\n",
       "      <th>hot_value</th>\n",
       "      <th>cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>6647582024964068622</td>\n",
       "      <td>1</td>\n",
       "      <td>甩头发换装</td>\n",
       "      <td>11782203</td>\n",
       "      <td><img src=\"https://p3-dy.byteimg.com/img/tos-cn-p-0015/7b9d003d625f4c82af8a4a696693f690~noop.jpeg?from=711472437\" width=\"60\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6799126825244038407</td>\n",
       "      <td>1</td>\n",
       "      <td>一个人前后反差可以有多大</td>\n",
       "      <td>8092958</td>\n",
       "      <td><img src=\"https://p3-dy.byteimg.com/img/tos-cn-p-0015/20266dc0a7164cee84745073c7663be5~noop.jpeg?from=711472437\" width=\"60\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>6797941205557581067</td>\n",
       "      <td>1</td>\n",
       "      <td>刑释人员离汉抵京调查结果</td>\n",
       "      <td>7571719</td>\n",
       "      <td><img src=\"https://p3-dy.byteimg.com/img/tos-cn-p-0015/7786acea03dd4eed8b14afa8ea203b41~noop.jpeg?from=711472437\" width=\"60\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word means the title of the topic\n",
    "generate_path('./trend')\n",
    "trend['cover']=['<img src=\"'+ str(i) + '\" width=\"60\" >' for i in Word_cover]\n",
    "trend_visual = HTML(trend.head(3).to_html(escape=False ,formatters=trend['cover']))\n",
    "trend.to_html('./trend/trend_'+last_update+'.html', escape=False)\n",
    "trend.to_csv('./trend/trend_'+last_update+'.csv',encoding = 'utf-8-sig', index = False)\n",
    "trend_visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Video\n",
    "- With functions as follows, we can get variabels of description, account name, verify, share count, forward count, like count, comment count, and download count of each video;\n",
    "- And download original videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video(video_url,file_name):\n",
    "    return urllib.request.urlretrieve(video_url,file_name)\n",
    "def cover(cover_url,file_name):\n",
    "    return urllib.request.urlretrieve(cover_url,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def douyin(topic):\n",
    "    generate_path('./'+topic)\n",
    "    topic_api='https://aweme-hl.snssdk.com/aweme/v1/hot/search/video/list/?hotword='\n",
    "    re=requests.get(topic_api+topic)\n",
    "    soup=bs.BeautifulSoup(re.content,'html.parser')\n",
    "    data = json.loads(soup.text)\n",
    "    data = data['aweme_list']\n",
    "    desc = [info['desc'] for info in data]\n",
    "    nickname = [info['author']['nickname'] for info in data]\n",
    "    verify = [info['author']['custom_verify'] for info in data]\n",
    "    share_count = [info['statistics']['share_count'] for info in data]\n",
    "    forward_count = [info['statistics']['forward_count'] for info in data]\n",
    "    like_count = [info['statistics']['digg_count'] for info in data]\n",
    "    comment_count = [info['statistics']['comment_count'] for info in data]\n",
    "    download_count = [info['statistics']['download_count'] for info in data]\n",
    "    cover_url = [info['video']['cover']['url_list'][0] for info in data]\n",
    "    cover_visual = ['<img src=\"'+ url + '\" width=\"100\" >' for url in cover_url]\n",
    "    video_url = []\n",
    "    for info in data:\n",
    "        video_url.append([i for i in info['video']['download_addr']['url_list'] if 'default' in i][0])\n",
    "    df=pd.DataFrame({'desc':desc,'nickname':nickname,'verify':verify,\n",
    "                    'share_count':share_count,'forward_count':forward_count,\n",
    "                    'like_count':like_count,'comment_count':comment_count,\n",
    "                    'download_count':download_count,'video_url':video_url,\n",
    "                    'cover_visual':cover_visual})\n",
    "    df.to_csv('./'+topic+'/'+topic+'.csv',encoding='utf-8-sig',index=False)\n",
    "    df.to_html('./'+topic+'/'+topic+'.html',escape=False)\n",
    "    video_visual = HTML(df.to_html(escape=False ,formatters=df['cover_visual']))\n",
    "    num=0\n",
    "    for video_url in df['video_url']:\n",
    "        video(video_url,'./'+topic+'/'+str(num)+'.mp4')\n",
    "        num = num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['甩头发换装', '一个人前后反差可以有多大', '刑释人员离汉抵京调查结果', '新冠肺炎逝者遗体解剖医生刘良', '李易峰本峰的压尾指挑战', '李现刮胡子前后', '刘宇宁黑夜一束光MV', '易烊千玺眼中稳定的工作', '王鹤棣剃光头', '任嘉伦谭松韵合唱六月的雨', '陈数吐槽崔英俊', '周震南童颜的忧伤', '日本多地超市厕纸被抢购一空', '王笑飞腹部扎入3厘米木刺坚持完赛', '法国两名市长确诊新冠肺炎', '王源杂志拍摄花絮', '易烊千玺 GQ封面', '张浩模仿郭德纲发型', '詹姆斯单挑锡安', '夏之光说合肥话', '斯黛拉崔英俊叶东烈直播喊话', '王嘉尔回应被催婚', '詹姆斯超远三分', '欧阳娜娜三姐妹合跳Anysong', '陈瑶收行李打脸岳绮罗', '脱口秀大会斥责白凯南抄袭', '李诞一分钟画李诞', '甜茶 复古油画大片', '蔡徐坤 汤姆猫', '官方回应街道搬走业主认捐蔬菜', '民警硬核警示掉进冰面暗坑', '皇马2比0胜巴萨', 'C罗重返伯纳乌观战国家德比', '戚薇火锅牌泡脚', '霍尊回应下巴脱臼', '计算机模拟疫情期开学的可能后果', '不同地方女生遇到男友前任的反应', '李佳航 老婆说我跳舞像秧歌', '意大利议员戴口罩被嘲怒摔话筒', '黄绮珊为奇迹男孩献唱', '武汉医院的东北话教学', '女孩子笑声的正确打开方式', '宋茜宋威龙好甜', '日本累计确诊新冠肺炎962例', '商业房贷利率可以二选一', '湖北接收社会捐赠资金超130亿元', '武汉儿童医院成立陪护专班', '意大利网红奶奶科普防护指南', '任嘉伦不会滑旱冰']\n"
     ]
    }
   ],
   "source": [
    "print(list(trend['word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with one single topic\n",
    "douyin('Your topic here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the whole data of all topics\n",
    "for i in trend['word']:\n",
    "    douyin(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
